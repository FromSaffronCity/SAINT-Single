{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOirSxrM4V5P"
   },
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend, callbacks\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import add, Add, BatchNormalization, Concatenate, Convolution1D, Dense, Dot, Dropout, Embedding, Input, Lambda, Layer, LayerNormalization, Permute, RepeatVector, Softmax, TimeDistributed\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import ast\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PeiV9KK4rOc"
   },
   "source": [
    "### Performance Evaluation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8-state (Q8) Secondary Structure Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_categorical_cross_entropy(y_true, y_predicted):\n",
    "    mask = backend.sum(y_true, axis=2)\n",
    "\n",
    "    loss = backend.sum(y_true * backend.log(y_predicted + sys.float_info.epsilon), axis=2)\n",
    "    loss = backend.sum(loss * mask, axis=1)\n",
    "\n",
    "    return -1 * backend.sum(loss, axis=0)\n",
    "\n",
    "def average_accuracy(y_true, y_predicted):\n",
    "    mask = backend.sum(y_true, axis=2)\n",
    "\n",
    "    y_true_labels, y_predicted_labels = backend.cast(backend.argmax(y_true, axis=2), \"int8\"), backend.cast(backend.argmax(y_predicted, axis=2), \"int8\")\n",
    "\n",
    "    is_identical = backend.cast(backend.equal(y_true_labels, y_predicted_labels), \"float32\")\n",
    "    num_identicals, protein_lengths = backend.sum(is_identical * mask, axis=1), backend.sum(mask, axis=1)\n",
    "\n",
    "    return backend.mean(num_identicals / protein_lengths, axis=0)\n",
    "\n",
    "def total_accuracy(y_true, y_predicted):\n",
    "    mask = backend.sum(y_true, axis=2)\n",
    "\n",
    "    y_true_labels, y_predicted_labels = backend.cast(backend.argmax(y_true, axis=2), \"int8\"), backend.cast(backend.argmax(y_predicted, axis=2), \"int8\")\n",
    "\n",
    "    is_identical = backend.cast(backend.equal(y_true_labels, y_predicted_labels), \"float32\")\n",
    "    num_identicals, protein_lengths = backend.sum(is_identical * mask, axis=1), backend.sum(mask, axis=1)\n",
    "\n",
    "    return backend.sum(num_identicals, axis=0) / backend.sum(protein_lengths, axis=0)\n",
    "\n",
    "def total_correct_prediction(y_true, y_predicted):\n",
    "    mask = backend.sum(y_true, axis=2)\n",
    "\n",
    "    y_true_labels, y_predicted_labels = backend.cast(backend.argmax(y_true, axis=2), \"int8\"), backend.cast(backend.argmax(y_predicted, axis=2), \"int8\")\n",
    "\n",
    "    is_identical = backend.cast(backend.equal(y_true_labels, y_predicted_labels), \"float32\")\n",
    "    num_identicals = backend.sum(is_identical * mask, axis=1)\n",
    "    \n",
    "    return backend.sum(num_identicals, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backbone Torsion φ and ψ Angles Prediction\n",
    "\n",
    "**Performance Metrics:-**\n",
    "- `tse` -> *Total Squared Error (TSE)*\n",
    "- `mse` -> *Mean Squared Error (MSE)*\n",
    "- `mae` -> *Mean Absolute Error (MAE)*\n",
    "- `sae` -> *Sum of Absolute Error (SAE)* = *MAE* * `total_residue_count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 661,
     "status": "ok",
     "timestamp": 1626118419243,
     "user": {
      "displayName": "Ajmain Yasar Ahmed Sahil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhSM2dxDJYHZ6ZaHCv0Wlos6xRR8j3VJXaJvbFcAA=s64",
      "userId": "13220418008390383455"
     },
     "user_tz": -360
    },
    "id": "8Xey9ZioFm2E"
   },
   "outputs": [],
   "source": [
    "def total_tse(y_true, y_predicted):\n",
    "    mask = 1 - backend.cast(backend.equal(y_true[:, :, 0], -500), dtype=\"float32\")\n",
    "    \n",
    "    y_true_phi_sine, y_true_phi_cosine = y_true[:, :, 0] * mask, y_true[:, :, 1] * mask\n",
    "    y_true_psi_sine, y_true_psi_cosine = y_true[:, :, 2] * mask, y_true[:, :, 3] * mask\n",
    "    y_pred_phi_sine, y_pred_phi_cosine = y_predicted[:, :, 0] * mask, y_predicted[:, :, 1] * mask\n",
    "    y_pred_psi_sine, y_pred_psi_cosine = y_predicted[:, :, 2] * mask, y_predicted[:, :, 3] * mask\n",
    "    \n",
    "    phi_diff_sine, phi_diff_cosine = backend.abs(y_true_phi_sine - y_pred_phi_sine), backend.abs(y_true_phi_cosine - y_pred_phi_cosine)\n",
    "    psi_diff_sine, psi_diff_cosine = backend.abs(y_true_psi_sine - y_pred_psi_sine), backend.abs(y_true_psi_cosine - y_pred_psi_cosine)\n",
    "    phi_mse_sine, phi_mse_cosine = backend.sum(backend.square(phi_diff_sine)), backend.sum(backend.square(phi_diff_cosine))\n",
    "    psi_mse_sine, psi_mse_cosine = backend.sum(backend.square(psi_diff_sine)), backend.sum(backend.square(psi_diff_cosine))\n",
    "    \n",
    "    return phi_mse_sine + phi_mse_cosine + psi_mse_sine + psi_mse_cosine\n",
    "\n",
    "def mean_tse(y_true, y_predicted):\n",
    "    mask = 1 - backend.cast(backend.equal(y_true[:, :, 0], -500), dtype=\"float32\")\n",
    "    \n",
    "    y_true_phi_sine, y_true_phi_cosine = y_true[:, :, 0] * mask, y_true[:, :, 1] * mask\n",
    "    y_true_psi_sine, y_true_psi_cosine = y_true[:, :, 2] * mask, y_true[:, :, 3] * mask\n",
    "    y_pred_phi_sine, y_pred_phi_cosine = y_predicted[:, :, 0] * mask, y_predicted[:, :, 1] * mask\n",
    "    y_pred_psi_sine, y_pred_psi_cosine = y_predicted[:, :, 2] * mask, y_predicted[:, :, 3] * mask\n",
    "    \n",
    "    phi_diff_sine, phi_diff_cosine = backend.abs(y_true_phi_sine - y_pred_phi_sine), backend.abs(y_true_phi_cosine - y_pred_phi_cosine)\n",
    "    psi_diff_sine, psi_diff_cosine = backend.abs(y_true_psi_sine - y_pred_psi_sine), backend.abs(y_true_psi_cosine - y_pred_psi_cosine)\n",
    "    phi_mse_sine, phi_mse_cosine = backend.sum(backend.square(phi_diff_sine)), backend.sum(backend.square(phi_diff_cosine))\n",
    "    psi_mse_sine, psi_mse_cosine = backend.sum(backend.square(psi_diff_sine)), backend.sum(backend.square(psi_diff_cosine))\n",
    "    \n",
    "    return 0.25 * (phi_mse_sine + phi_mse_cosine + psi_mse_sine + psi_mse_cosine)\n",
    "\n",
    "def total_mse(y_true, y_predicted):\n",
    "    mask = 1 - backend.cast(backend.equal(y_true[:, :, 0], -500), dtype=\"float32\")\n",
    "    total_residue_count = backend.sum(mask)\n",
    "\n",
    "    y_true_phi_sine, y_true_phi_cosine = y_true[:, :, 0] * mask, y_true[:, :, 1] * mask\n",
    "    y_true_psi_sine, y_true_psi_cosine = y_true[:, :, 2] * mask, y_true[:, :, 3] * mask\n",
    "    y_pred_phi_sine, y_pred_phi_cosine = y_predicted[:, :, 0] * mask, y_predicted[:, :, 1] * mask\n",
    "    y_pred_psi_sine, y_pred_psi_cosine = y_predicted[:, :, 2] * mask, y_predicted[:, :, 3] * mask\n",
    "\n",
    "    phi_diff_sine, phi_diff_cosine = backend.abs(y_true_phi_sine - y_pred_phi_sine), backend.abs(y_true_phi_cosine - y_pred_phi_cosine)\n",
    "    psi_diff_sine, psi_diff_cosine = backend.abs(y_true_psi_sine - y_pred_psi_sine), backend.abs(y_true_psi_cosine - y_pred_psi_cosine)\n",
    "    phi_mse_sine, phi_mse_cosine = backend.sum(backend.square(phi_diff_sine)) / total_residue_count, backend.sum(backend.square(phi_diff_cosine)) / total_residue_count\n",
    "    psi_mse_sine, psi_mse_cosine = backend.sum(backend.square(psi_diff_sine)) / total_residue_count, backend.sum(backend.square(psi_diff_cosine)) / total_residue_count\n",
    "\n",
    "    total_mse = phi_mse_sine + phi_mse_cosine + psi_mse_sine + psi_mse_cosine\n",
    "    return total_mse\n",
    "\n",
    "def mean_mse(y_true, y_predicted):\n",
    "    mask = 1 - backend.cast(backend.equal(y_true[:, :, 0], -500), dtype=\"float32\")\n",
    "    total_residue_count = backend.sum(mask)\n",
    "\n",
    "    y_true_phi_sine, y_true_phi_cosine = y_true[:, :, 0] * mask, y_true[:, :, 1] * mask\n",
    "    y_true_psi_sine, y_true_psi_cosine = y_true[:, :, 2] * mask, y_true[:, :, 3] * mask\n",
    "    y_pred_phi_sine, y_pred_phi_cosine = y_predicted[:, :, 0] * mask, y_predicted[:, :, 1] * mask\n",
    "    y_pred_psi_sine, y_pred_psi_cosine = y_predicted[:, :, 2] * mask, y_predicted[:, :, 3] * mask\n",
    "\n",
    "    phi_diff_sine, phi_diff_cosine = backend.abs(y_true_phi_sine - y_pred_phi_sine), backend.abs(y_true_phi_cosine - y_pred_phi_cosine)\n",
    "    psi_diff_sine, psi_diff_cosine = backend.abs(y_true_psi_sine - y_pred_psi_sine), backend.abs(y_true_psi_cosine - y_pred_psi_cosine)\n",
    "    phi_mse_sine, phi_mse_cosine = backend.sum(backend.square(phi_diff_sine)) / total_residue_count, backend.sum(backend.square(phi_diff_cosine)) / total_residue_count\n",
    "    psi_mse_sine, psi_mse_cosine = backend.sum(backend.square(psi_diff_sine)) / total_residue_count, backend.sum(backend.square(psi_diff_cosine)) / total_residue_count\n",
    "\n",
    "    mean_mse = 0.25 * (phi_mse_sine + phi_mse_cosine + psi_mse_sine + psi_mse_cosine)\n",
    "    return mean_mse\n",
    "\n",
    "def mean_mae(y_true, y_predicted):\n",
    "    y_true_phi_angle = tf.atan2(y_true[:, :, 0], y_true[:, :, 1]) * 180 / np.pi\n",
    "    y_pred_phi_angle = tf.atan2(y_predicted[:, :, 0], y_predicted[:, :, 1]) * 180 / np.pi\n",
    "    y_true_psi_angle = tf.atan2(y_true[:, :, 2], y_true[:, :, 3]) * 180 / np.pi\n",
    "    y_pred_psi_angle = tf.atan2(y_predicted[:, :, 2], y_predicted[:, :, 3]) * 180 / np.pi\n",
    "\n",
    "    mask = 1 - backend.cast(backend.equal(y_true[:, :, 0], -500), dtype=\"float32\")\n",
    "    total_residue_count = backend.sum(mask)\n",
    "\n",
    "    phi_diff, psi_diff = backend.abs(y_true_phi_angle - y_pred_phi_angle), backend.abs(y_true_psi_angle - y_pred_psi_angle)\n",
    "    phi_diff_rev, psi_diff_rev = Lambda(lambda x: 360 - x)(phi_diff), Lambda(lambda x: 360 - x)(psi_diff)\n",
    "\n",
    "    phi_mask = backend.cast(backend.greater(phi_diff[:, :], 180), dtype=\"float32\")\n",
    "    phi_mask_rev = 1 - phi_mask\n",
    "    psi_mask = backend.cast(backend.greater(psi_diff[:, :], 180), dtype=\"float32\")\n",
    "    psi_mask_rev = 1 - psi_mask\n",
    "\n",
    "    phi_error, psi_error = phi_diff * phi_mask_rev + phi_diff_rev * phi_mask, psi_diff * psi_mask_rev + psi_diff_rev * psi_mask\n",
    "    phi_mae, psi_mae = backend.sum(phi_error * mask) / total_residue_count, backend.sum(psi_error * mask) / total_residue_count\n",
    "\n",
    "    mean_mae = 0.5 * (phi_mae + psi_mae)\n",
    "    return mean_mae\n",
    "\n",
    "def phi_mae(y_true, y_predicted):\n",
    "    y_true_phi_angle = tf.atan2(y_true[:, :, 0], y_true[:, :, 1]) * 180 / np.pi\n",
    "    y_pred_phi_angle = tf.atan2(y_predicted[:, :, 0], y_predicted[:, :, 1]) * 180 / np.pi\n",
    "\n",
    "    mask = 1 - backend.cast(backend.equal(y_true[:, :, 0], -500), dtype=\"float32\")\n",
    "    total_residue_count = backend.sum(mask)\n",
    "\n",
    "    phi_diff = backend.abs(y_true_phi_angle - y_pred_phi_angle)\n",
    "    phi_diff_rev = Lambda(lambda x: 360 - x)(phi_diff)\n",
    "\n",
    "    phi_mask = backend.cast(backend.greater(phi_diff[:, :], 180), dtype=\"float32\")\n",
    "    phi_mask_rev = 1 - phi_mask\n",
    "\n",
    "    phi_error = phi_diff * phi_mask_rev + phi_diff_rev * phi_mask\n",
    "    phi_mae = backend.sum(phi_error * mask) / total_residue_count\n",
    "    return phi_mae\n",
    "\n",
    "def psi_mae(y_true, y_predicted):\n",
    "    y_true_psi_angle = tf.atan2(y_true[:, :, 2], y_true[:, :, 3]) * 180 / np.pi\n",
    "    y_pred_psi_angle = tf.atan2(y_predicted[:, :, 2], y_predicted[:, :, 3]) * 180 / np.pi\n",
    "    \n",
    "    mask = 1 - backend.cast(backend.equal(y_true[:, :, 0], -500), dtype=\"float32\")\n",
    "    total_residue_count = backend.sum(mask)\n",
    "    \n",
    "    psi_diff = backend.abs(y_true_psi_angle - y_pred_psi_angle)\n",
    "    psi_diff_rev = Lambda(lambda x: 360 - x)(psi_diff)\n",
    "    \n",
    "    psi_mask = backend.cast(backend.greater(psi_diff[:, :], 180), dtype=\"float32\")\n",
    "    psi_mask_rev = 1 - psi_mask\n",
    "\n",
    "    psi_error = psi_diff * psi_mask_rev + psi_diff_rev * psi_mask\n",
    "    psi_mae = backend.sum(psi_error * mask) / total_residue_count\n",
    "    return psi_mae\n",
    "\n",
    "def mean_sae(y_true, y_predicted):\n",
    "    y_true_phi_angle = tf.atan2(y_true[:, :, 0], y_true[:, :, 1]) * 180 / np.pi\n",
    "    y_pred_phi_angle = tf.atan2(y_predicted[:, :, 0], y_predicted[:, :, 1]) * 180 / np.pi\n",
    "    y_true_psi_angle = tf.atan2(y_true[:, :, 2], y_true[:, :, 3]) * 180 / np.pi\n",
    "    y_pred_psi_angle = tf.atan2(y_predicted[:, :, 2], y_predicted[:, :, 3]) * 180 / np.pi\n",
    "\n",
    "    mask = 1 - backend.cast(backend.equal(y_true[:, :, 0], -500), dtype=\"float32\")\n",
    "\n",
    "    phi_diff, psi_diff = backend.abs(y_true_phi_angle - y_pred_phi_angle), backend.abs(y_true_psi_angle - y_pred_psi_angle)\n",
    "    phi_diff_rev, psi_diff_rev = Lambda(lambda x: 360 - x)(phi_diff), Lambda(lambda x: 360 - x)(psi_diff)\n",
    "\n",
    "    phi_mask = backend.cast(backend.greater(phi_diff[:, :], 180), dtype=\"float32\")\n",
    "    phi_mask_rev = 1 - phi_mask\n",
    "    psi_mask = backend.cast(backend.greater(psi_diff[:, :], 180), dtype=\"float32\")\n",
    "    psi_mask_rev = 1 - psi_mask\n",
    "\n",
    "    phi_error, psi_error = phi_diff * phi_mask_rev + phi_diff_rev * phi_mask, psi_diff * psi_mask_rev + psi_diff_rev * psi_mask\n",
    "    phi_sae, psi_sae = backend.sum(phi_error * mask), backend.sum(psi_error * mask)\n",
    "    \n",
    "    mean_sae = 0.5 * (phi_sae + psi_sae)\n",
    "    return mean_sae\n",
    "\n",
    "def phi_sae(y_true, y_predicted):\n",
    "    y_true_phi_angle = tf.atan2(y_true[:, :, 0], y_true[:, :, 1]) * 180 / np.pi\n",
    "    y_pred_phi_angle = tf.atan2(y_predicted[:, :, 0], y_predicted[:, :, 1]) * 180 / np.pi\n",
    "    \n",
    "    mask = 1 - backend.cast(backend.equal(y_true[:, :, 0], -500), dtype=\"float32\")\n",
    "    \n",
    "    phi_diff = backend.abs(y_true_phi_angle - y_pred_phi_angle)\n",
    "    phi_diff_rev = Lambda(lambda x: 360 - x)(phi_diff)\n",
    "\n",
    "    phi_mask = backend.cast(backend.greater(phi_diff[:, :], 180), dtype=\"float32\")\n",
    "    phi_mask_rev = 1 - phi_mask\n",
    "\n",
    "    phi_error = phi_diff * phi_mask_rev + phi_diff_rev * phi_mask\n",
    "    phi_sae = backend.sum(phi_error * mask)\n",
    "    return phi_sae\n",
    "\n",
    "def psi_sae(y_true, y_predicted):\n",
    "    y_true_psi_angle = tf.atan2(y_true[:, :, 2], y_true[:, :, 3]) * 180 / np.pi\n",
    "    y_pred_psi_angle = tf.atan2(y_predicted[:, :, 2], y_predicted[:, :, 3]) * 180 / np.pi\n",
    "\n",
    "    mask = 1 - backend.cast(backend.equal(y_true[:, :, 0], -500), dtype=\"float32\")\n",
    "\n",
    "    psi_diff = backend.abs(y_true_psi_angle - y_pred_psi_angle)\n",
    "    psi_diff_rev = Lambda(lambda x: 360 - x)(psi_diff)\n",
    "\n",
    "    psi_mask = backend.cast(backend.greater(psi_diff[:, :], 180), dtype=\"float32\")\n",
    "    psi_mask_rev = 1 - psi_mask\n",
    "\n",
    "    psi_error = psi_diff * psi_mask_rev + psi_diff_rev * psi_mask\n",
    "    psi_sae = backend.sum(psi_error * mask)\n",
    "    return psi_sae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `NumPy` Implementation of Performance Evaluation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8-state (Q8) Secondary Structure Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_accuracy_numpy(y_true, y_predicted):\n",
    "    mask = np.sum(y_true, axis=2)\n",
    "    \n",
    "    y_true_labels, y_predicted_labels = np.argmax(y_true, axis=2).astype(np.int8), np.argmax(y_predicted, axis=2).astype(np.int8)\n",
    "    \n",
    "    is_identical = np.equal(y_true_labels, y_predicted_labels).astype(np.float32)\n",
    "    num_identicals, protein_lengths = np.sum(is_identical * mask, axis=1), np.sum(mask, axis=1)\n",
    "    \n",
    "    return np.mean(num_identicals / protein_lengths, axis=0)\n",
    "\n",
    "def total_accuracy_numpy(y_true, y_predicted):\n",
    "    mask = np.sum(y_true, axis=2)\n",
    "    \n",
    "    y_true_labels, y_predicted_labels = np.argmax(y_true, axis=2).astype(np.int8), np.argmax(y_predicted, axis=2).astype(np.int8)\n",
    "    \n",
    "    is_identical = np.equal(y_true_labels, y_predicted_labels).astype(np.float32)\n",
    "    num_identicals, protein_lengths = np.sum(is_identical * mask, axis=1), np.sum(mask, axis=1)\n",
    "    \n",
    "    return np.sum(num_identicals, axis=0) / np.sum(protein_lengths, axis=0)\n",
    "\n",
    "def total_correct_prediction_numpy(y_true, y_predicted):\n",
    "    mask = np.sum(y_true, axis=2)\n",
    "    \n",
    "    y_true_labels, y_predicted_labels = np.argmax(y_true, axis=2).astype(np.int8), np.argmax(y_predicted, axis=2).astype(np.int8)\n",
    "    \n",
    "    is_identical = np.equal(y_true_labels, y_predicted_labels).astype(np.float32)\n",
    "    num_identicals = np.sum(is_identical * mask, axis=1)\n",
    "    \n",
    "    return np.sum(num_identicals, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backbone Torsion φ and ψ Angles Prediction\n",
    "\n",
    "**Performance Metrics:-**\n",
    "- `mae` -> *Mean Absolute Error (MAE)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_mae_numpy_train(y_true, y_predicted):\n",
    "    y_true_phi_angle = np.arctan2(y_true[:, :, 0], y_true[:, :, 1]) * 180 / np.pi\n",
    "    y_pred_phi_angle = np.arctan2(y_predicted[:, :, 0], y_predicted[:, :, 1]) * 180 / np.pi\n",
    "    y_true_psi_angle = np.arctan2(y_true[:, :, 2], y_true[:, :, 3]) * 180 / np.pi\n",
    "    y_pred_psi_angle = np.arctan2(y_predicted[:, :, 2], y_predicted[:, :, 3]) * 180 / np.pi\n",
    "    \n",
    "    mask = 1 - np.equal(y_true[:, :, 0], -500).astype(np.float32)\n",
    "    total_residue_count = np.sum(mask)\n",
    "    \n",
    "    phi_diff, psi_diff = np.abs(y_true_phi_angle - y_pred_phi_angle), np.abs(y_true_psi_angle - y_pred_psi_angle)\n",
    "    \n",
    "    revert_difference = lambda x: 360 - x\n",
    "    phi_diff_rev, psi_diff_rev = revert_difference(phi_diff), revert_difference(psi_diff)\n",
    "    \n",
    "    phi_mask = np.greater(phi_diff[:, :], 180).astype(np.float32)\n",
    "    phi_mask_rev = 1 - phi_mask\n",
    "    psi_mask = np.greater(psi_diff[:, :], 180).astype(np.float32)\n",
    "    psi_mask_rev = 1 - psi_mask\n",
    "    \n",
    "    phi_error, psi_error = phi_diff * phi_mask_rev + phi_diff_rev * phi_mask, psi_diff * psi_mask_rev + psi_diff_rev * psi_mask\n",
    "    phi_mae, psi_mae = np.sum(phi_error * mask) / total_residue_count, np.sum(psi_error * mask) / total_residue_count\n",
    "    \n",
    "    mean_mae = 0.5 * (phi_mae + psi_mae)\n",
    "    return mean_mae\n",
    "\n",
    "def phi_mae_numpy_train(y_true, y_predicted):\n",
    "    y_true_phi_angle = np.arctan2(y_true[:, :, 0], y_true[:, :, 1]) * 180 / np.pi\n",
    "    y_pred_phi_angle = np.arctan2(y_predicted[:, :, 0], y_predicted[:, :, 1]) * 180 / np.pi\n",
    "    \n",
    "    mask = 1 - np.equal(y_true[:, :, 0], -500).astype(np.float32)\n",
    "    total_residue_count = np.sum(mask)\n",
    "    \n",
    "    phi_diff = np.abs(y_true_phi_angle - y_pred_phi_angle)\n",
    "    \n",
    "    revert_difference = lambda x: 360 - x\n",
    "    phi_diff_rev = revert_difference(phi_diff)\n",
    "    \n",
    "    phi_mask = np.greater(phi_diff[:, :], 180).astype(np.float32)\n",
    "    phi_mask_rev = 1 - phi_mask\n",
    "    \n",
    "    phi_error = phi_diff * phi_mask_rev + phi_diff_rev * phi_mask\n",
    "    phi_mae = np.sum(phi_error * mask) / total_residue_count\n",
    "    \n",
    "    return phi_mae\n",
    "\n",
    "def psi_mae_numpy_train(y_true, y_predicted):\n",
    "    y_true_psi_angle = np.arctan2(y_true[:, :, 2], y_true[:, :, 3]) * 180 / np.pi\n",
    "    y_pred_psi_angle = np.arctan2(y_predicted[:, :, 2], y_predicted[:, :, 3]) * 180 / np.pi\n",
    "    \n",
    "    mask = 1 - np.equal(y_true[:, :, 0], -500).astype(np.float32)\n",
    "    total_residue_count = np.sum(mask)\n",
    "    \n",
    "    psi_diff = np.abs(y_true_psi_angle - y_pred_psi_angle)\n",
    "    \n",
    "    revert_difference = lambda x: 360 - x\n",
    "    psi_diff_rev = revert_difference(psi_diff)\n",
    "    \n",
    "    psi_mask = np.greater(psi_diff[:, :], 180).astype(np.float32)\n",
    "    psi_mask_rev = 1 - psi_mask\n",
    "    \n",
    "    psi_error = psi_diff * psi_mask_rev + psi_diff_rev * psi_mask\n",
    "    psi_mae = np.sum(psi_error * mask) / total_residue_count\n",
    "    \n",
    "    return psi_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_mae_numpy_test(y_true, y_predicted):\n",
    "    y_true_phi_angle = np.arctan2(y_true[:, :, 0], y_true[:, :, 1]) * 180 / np.pi\n",
    "    y_pred_phi_angle = np.arctan2(y_predicted[:, :, 0], y_predicted[:, :, 1]) * 180 / np.pi\n",
    "    y_true_psi_angle = np.arctan2(y_true[:, :, 2], y_true[:, :, 3]) * 180 / np.pi\n",
    "    y_pred_psi_angle = np.arctan2(y_predicted[:, :, 2], y_predicted[:, :, 3]) * 180 / np.pi\n",
    "    \n",
    "    phi_angle_mask = 1 - np.equal(y_true[:, :, 0], -500).astype(np.float32)\n",
    "    psi_angle_mask = 1 - np.equal(y_true[:, :, 2], -500).astype(np.float32)\n",
    "    phi_total_residue_count = np.sum(phi_angle_mask)\n",
    "    psi_total_residue_count = np.sum(psi_angle_mask)\n",
    "    \n",
    "    phi_diff, psi_diff = np.abs(y_true_phi_angle - y_pred_phi_angle), np.abs(y_true_psi_angle - y_pred_psi_angle)\n",
    "    \n",
    "    revert_difference = lambda x: 360 - x\n",
    "    phi_diff_rev, psi_diff_rev = revert_difference(phi_diff), revert_difference(psi_diff)\n",
    "    \n",
    "    phi_mask = np.greater(phi_diff[:, :], 180).astype(np.float32)\n",
    "    phi_mask_rev = 1 - phi_mask\n",
    "    psi_mask = np.greater(psi_diff[:, :], 180).astype(np.float32)\n",
    "    psi_mask_rev = 1 - psi_mask\n",
    "    \n",
    "    phi_error, psi_error = phi_diff * phi_mask_rev + phi_diff_rev * phi_mask, psi_diff * psi_mask_rev + psi_diff_rev * psi_mask\n",
    "    phi_mae, psi_mae = np.sum(phi_error * phi_angle_mask) / phi_total_residue_count, np.sum(psi_error * psi_angle_mask) / psi_total_residue_count\n",
    "    \n",
    "    mean_mae = 0.5 * (phi_mae + psi_mae)\n",
    "    return mean_mae\n",
    "\n",
    "def phi_mae_numpy_test(y_true, y_predicted):\n",
    "    y_true_phi_angle = np.arctan2(y_true[:, :, 0], y_true[:, :, 1]) * 180 / np.pi\n",
    "    y_pred_phi_angle = np.arctan2(y_predicted[:, :, 0], y_predicted[:, :, 1]) * 180 / np.pi\n",
    "    \n",
    "    phi_angle_mask = 1 - np.equal(y_true[:, :, 0], -500).astype(np.float32)\n",
    "    phi_total_residue_count = np.sum(phi_angle_mask)\n",
    "    \n",
    "    phi_diff = np.abs(y_true_phi_angle - y_pred_phi_angle)\n",
    "    \n",
    "    revert_difference = lambda x: 360 - x\n",
    "    phi_diff_rev = revert_difference(phi_diff)\n",
    "    \n",
    "    phi_mask = np.greater(phi_diff[:, :], 180).astype(np.float32)\n",
    "    phi_mask_rev = 1 - phi_mask\n",
    "    \n",
    "    phi_error = phi_diff * phi_mask_rev + phi_diff_rev * phi_mask\n",
    "    phi_mae = np.sum(phi_error * phi_angle_mask) / phi_total_residue_count\n",
    "    \n",
    "    return phi_mae\n",
    "\n",
    "def psi_mae_numpy_test(y_true, y_predicted):\n",
    "    y_true_psi_angle = np.arctan2(y_true[:, :, 2], y_true[:, :, 3]) * 180 / np.pi\n",
    "    y_pred_psi_angle = np.arctan2(y_predicted[:, :, 2], y_predicted[:, :, 3]) * 180 / np.pi\n",
    "    \n",
    "    psi_angle_mask = 1 - np.equal(y_true[:, :, 2], -500).astype(np.float32)\n",
    "    psi_total_residue_count = np.sum(psi_angle_mask)\n",
    "    \n",
    "    psi_diff = np.abs(y_true_psi_angle - y_pred_psi_angle)\n",
    "    \n",
    "    revert_difference = lambda x: 360 - x\n",
    "    psi_diff_rev = revert_difference(psi_diff)\n",
    "    \n",
    "    psi_mask = np.greater(psi_diff[:, :], 180).astype(np.float32)\n",
    "    psi_mask_rev = 1 - psi_mask\n",
    "    \n",
    "    psi_error = psi_diff * psi_mask_rev + psi_diff_rev * psi_mask\n",
    "    psi_mae = np.sum(psi_error * psi_angle_mask) / psi_total_residue_count\n",
    "    \n",
    "    return psi_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rb3u5tpY4gB0"
   },
   "source": [
    "### Utility Classes and Methods for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1626118418622,
     "user": {
      "displayName": "Ajmain Yasar Ahmed Sahil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhSM2dxDJYHZ6ZaHCv0Wlos6xRR8j3VJXaJvbFcAA=s64",
      "userId": "13220418008390383455"
     },
     "user_tz": -360
    },
    "id": "aDV0TdRRG58Y"
   },
   "outputs": [],
   "source": [
    "def get_shape_list(x):\n",
    "    if backend.backend() != \"theano\":\n",
    "        temp = backend.int_shape(x)\n",
    "    else:\n",
    "        temp = x.shape\n",
    "\n",
    "    temp = list(temp)\n",
    "    temp[0] = -1\n",
    "    return temp\n",
    "\n",
    "class CustomLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._x = None\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self._x = backend.variable(0.2)\n",
    "        self._x._trainable = True\n",
    "        self._trainable_weights = [self._x]\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x, **kwargs):\n",
    "        output_after_attention, previous_layer_input = x\n",
    "        result = add([self._x * output_after_attention, (1 - self._x) * previous_layer_input])\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]\n",
    "\n",
    "class TestDataLoader(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataset_path, dataset_name, features, num_features, batch_size):\n",
    "        self.dataset_path, self.dataset_name = dataset_path, dataset_name\n",
    "        self.features, self.num_features, self.batch_size = features, num_features, batch_size\n",
    "        self.proteins_dict, self.protein_names = OrderedDict(), None\n",
    "        \n",
    "        with open(dataset_path + os.sep + dataset_name + \"_below_700_proteins.txt\", 'r') as proteins_file:\n",
    "            for content in proteins_file.read().split('\\n'):\n",
    "                if content != '':\n",
    "                    protein_name, protein_length = content.split(',')\n",
    "                    self.proteins_dict[protein_name] = int(protein_length)\n",
    "        \n",
    "        self.protein_names = list(self.proteins_dict.keys())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.protein_names) / self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_protein_names = self.protein_names[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        \n",
    "        main_input = np.zeros(shape=(len(batch_protein_names), 700, self.num_features))\n",
    "        attention_mask = np.zeros(shape=(len(batch_protein_names), 700))\n",
    "        position_ids = np.zeros(shape=(len(batch_protein_names), 700))\n",
    "        weight_mask = np.ones(shape=(len(batch_protein_names), 700))\n",
    "        Q8_labels = np.zeros(shape=(len(batch_protein_names), 700, 8))\n",
    "        phi_psi_labels = np.zeros(shape=(len(batch_protein_names), 700, 4))\n",
    "        \n",
    "        for batch_index, protein_name in enumerate(batch_protein_names):\n",
    "            data_path = self.dataset_path + os.sep + \"Rawdata\" + os.sep + protein_name + os.sep + protein_name\n",
    "            protein_features = []\n",
    "            \n",
    "            for feature in self.features:\n",
    "                if self.features[feature][\"add_feature\"]:\n",
    "                    with open(data_path + '_' + self.features[feature][\"extension\"] + \".npy\", 'rb') as feature_file:\n",
    "                        protein_features.append(np.nan_to_num(np.load(file=feature_file), nan=0.0))\n",
    "            \n",
    "            main_input[batch_index, :self.proteins_dict[protein_name]] = np.concatenate(protein_features, axis=-1)\n",
    "            attention_mask[batch_index, self.proteins_dict[protein_name]:] = -np.inf\n",
    "            position_ids[batch_index] = np.arange(700)\n",
    "            weight_mask[batch_index, self.proteins_dict[protein_name]:] = 0\n",
    "        \n",
    "        return {\"main_input\": main_input, \"attention_mask\": attention_mask, \"position_ids\": position_ids}, {\"Q8_output\": Q8_labels, \"Phi_Psi_output\": phi_psi_labels}, weight_mask\n",
    "\n",
    "def load_labels_train(dataset_path, proteins_dict, protein_names):\n",
    "    Q8_labels = np.zeros(shape=(len(protein_names), 700, 8))\n",
    "    phi_psi_labels = np.full(shape=(len(protein_names), 700, 4), fill_value=-500, dtype=np.float32)\n",
    "    \n",
    "    for index, protein_name in enumerate(protein_names):\n",
    "        data_path = dataset_path + os.sep + \"Rawdata\" + os.sep + protein_name + os.sep + protein_name\n",
    "        \n",
    "        with open(data_path + \"_ss8.npy\", 'rb') as label_file:\n",
    "            Q8_labels[index, :proteins_dict[protein_name]] = np.load(file=label_file)\n",
    "        \n",
    "        with open(data_path + \"_phi.npy\", 'rb') as label_file:\n",
    "            phi_angles = np.load(file=label_file)\n",
    "            phi_angles = np.reshape(phi_angles, newshape=(-1,))\n",
    "        \n",
    "        with open(data_path + \"_psi.npy\", 'rb') as label_file:\n",
    "            psi_angles = np.load(file=label_file)\n",
    "            psi_angles = np.reshape(psi_angles, newshape=(-1,))\n",
    "        \n",
    "        phi_psi_labels[index, :proteins_dict[protein_name], 0] = np.sin(phi_angles * np.pi / 180)\n",
    "        phi_psi_labels[index, :proteins_dict[protein_name], 1] = np.cos(phi_angles * np.pi / 180)\n",
    "        phi_psi_labels[index, :proteins_dict[protein_name], 2] = np.sin(psi_angles * np.pi / 180)\n",
    "        phi_psi_labels[index, :proteins_dict[protein_name], 3] = np.cos(psi_angles * np.pi / 180)\n",
    "        \n",
    "        phi_psi_labels[index, np.where(phi_angles == -500), :] = -500\n",
    "        phi_psi_labels[index, np.where(psi_angles == -500), :] = -500\n",
    "        phi_psi_labels[index, 0, :] = -500\n",
    "        phi_psi_labels[index, proteins_dict[protein_name] - 1, :] = -500\n",
    "    \n",
    "    return Q8_labels, phi_psi_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels_test(dataset_path, proteins_dict, protein_names):\n",
    "    Q8_labels = np.zeros(shape=(len(protein_names), 700, 8))\n",
    "    phi_psi_labels = np.full(shape=(len(protein_names), 700, 4), fill_value=-500, dtype=np.float32)\n",
    "    \n",
    "    for index, protein_name in enumerate(protein_names):\n",
    "        data_path = dataset_path + os.sep + \"Rawdata\" + os.sep + protein_name + os.sep + protein_name\n",
    "        \n",
    "        with open(data_path + \"_ss8.npy\", 'rb') as label_file:\n",
    "            Q8_labels[index, :proteins_dict[protein_name]] = np.load(file=label_file)\n",
    "        \n",
    "        with open(data_path + \"_phi.npy\", 'rb') as label_file:\n",
    "            phi_angles = np.load(file=label_file)\n",
    "            phi_angles = np.reshape(phi_angles, newshape=(-1,))\n",
    "        \n",
    "        with open(data_path + \"_psi.npy\", 'rb') as label_file:\n",
    "            psi_angles = np.load(file=label_file)\n",
    "            psi_angles = np.reshape(psi_angles, newshape=(-1,))\n",
    "        \n",
    "        phi_psi_labels[index, :proteins_dict[protein_name], 0] = np.sin(phi_angles * np.pi / 180)\n",
    "        phi_psi_labels[index, :proteins_dict[protein_name], 1] = np.cos(phi_angles * np.pi / 180)\n",
    "        phi_psi_labels[index, :proteins_dict[protein_name], 2] = np.sin(psi_angles * np.pi / 180)\n",
    "        phi_psi_labels[index, :proteins_dict[protein_name], 3] = np.cos(psi_angles * np.pi / 180)\n",
    "        \n",
    "        phi_psi_labels[index, np.where(phi_angles == -500), :2] = -500\n",
    "        phi_psi_labels[index, np.where(psi_angles == -500), 2:] = -500\n",
    "        phi_psi_labels[index, 0, :2] = -500\n",
    "        phi_psi_labels[index, proteins_dict[protein_name] - 1, 2:] = -500\n",
    "    \n",
    "    return Q8_labels, phi_psi_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Parameters and Base Models Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_name = \"TEST2018\"\n",
    "test_set_path = \"../datasets/SPOT-1D/Features\" + os.sep + test_set_name\n",
    "test_batch_size = 1\n",
    "\n",
    "base_models = [\n",
    "    \"SAINT_Martin_Basic2_PSSM_HHM_PCP\", \n",
    "    \"SAINT_Martin_Basic2_PSSM_HHM_PCP_Win10\", \n",
    "    \"SAINT_Martin_Basic1_PT256_PSSM_HHM_PCP\", \n",
    "    \"SAINT_Martin_Basic1_PT256_PSSM_HHM_PCP_Win10\", \n",
    "    \"SAINT_Martin_Basic1_PT256_PSSM_HHM_PCP_Win20\", \n",
    "    \"SAINT_Martin_Basic1_PT256_PSSM_HHM_PCP_Win50\", \n",
    "    \"SAINT_Martin_Residual1_PT243_PSSM_HHM_PCP\", \n",
    "    \"SAINT_Martin_Residual1_PT227_PSSM_HHM_PCP_Win10\"\n",
    "]\n",
    "\n",
    "ensemble_name = \"Ensemble_SAINT-Angle_8\"\n",
    "compute_performance_metrics = False\n",
    "generate_predicted_labels = True\n",
    "\n",
    "custom_objects = {\n",
    "    \"CustomLayer\": CustomLayer, \n",
    "    \"backend\": backend, \n",
    "    \"get_shape_list\": get_shape_list, \n",
    "    \"custom_categorical_cross_entropy\": custom_categorical_cross_entropy, \n",
    "    \"average_accuracy\": average_accuracy, \n",
    "    \"total_accuracy\": total_accuracy, \n",
    "    \"total_correct_prediction\": total_correct_prediction, \n",
    "    \"total_tse\": total_tse, \n",
    "    \"mean_tse\": mean_tse, \n",
    "    \"total_mse\": total_mse, \n",
    "    \"mean_mse\": mean_mse, \n",
    "    \"mean_mae\": mean_mae, \n",
    "    \"phi_mae\": phi_mae, \n",
    "    \"psi_mae\": psi_mae, \n",
    "    \"mean_sae\": mean_sae, \n",
    "    \"phi_sae\": phi_sae, \n",
    "    \"psi_sae\": psi_sae\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions with Base Models and Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_proteins_dict, test_protein_names = None, None\n",
    "Q8_predictions, phi_psi_predictions = {}, {}\n",
    "\n",
    "inference_start_time = time.time()\n",
    "\n",
    "for base_model in base_models:\n",
    "    print(f\"Making prediction with {base_model}...\")\n",
    "    \n",
    "    with open(\"../Best_Model\" + os.sep + base_model + \"_args.txt\", 'r') as args_file:\n",
    "        args = ast.literal_eval(args_file.read())\n",
    "    \n",
    "    model = load_model(filepath=args[\"best_model_path\"], custom_objects=custom_objects)\n",
    "    test_dataloader = TestDataLoader(dataset_path=test_set_path, dataset_name=test_set_name, features=args[\"features\"], num_features=args[\"num_features\"], batch_size=test_batch_size)\n",
    "    \n",
    "    if test_proteins_dict is None:\n",
    "        test_proteins_dict = test_dataloader.proteins_dict\n",
    "    \n",
    "    if test_protein_names is None:\n",
    "        test_protein_names = test_dataloader.protein_names\n",
    "    \n",
    "    for global_protein_name, local_protein_name in zip(test_protein_names, test_dataloader.protein_names):\n",
    "        assert global_protein_name == local_protein_name\n",
    "    \n",
    "    Q8_prediction, phi_psi_prediction = model.predict(x=test_dataloader)\n",
    "    Q8_predictions[base_model], phi_psi_predictions[base_model] = Q8_prediction, phi_psi_prediction\n",
    "\n",
    "if compute_performance_metrics:\n",
    "    Q8_labels_train, phi_psi_labels_train = load_labels_train(dataset_path=test_set_path, proteins_dict=test_proteins_dict, protein_names=test_protein_names)\n",
    "    Q8_labels_test, phi_psi_labels_test = load_labels_test(dataset_path=test_set_path, proteins_dict=test_proteins_dict, protein_names=test_protein_names)\n",
    "\n",
    "ensemble_Q8_prediction, ensemble_phi_psi_prediction = None, None\n",
    "\n",
    "for base_model in base_models:\n",
    "    if ensemble_Q8_prediction is None:\n",
    "        ensemble_Q8_prediction = Q8_predictions[base_model]\n",
    "    else:\n",
    "        ensemble_Q8_prediction = ensemble_Q8_prediction + Q8_predictions[base_model]\n",
    "    \n",
    "    if ensemble_phi_psi_prediction is None:\n",
    "        ensemble_phi_psi_prediction = phi_psi_predictions[base_model]\n",
    "    else:\n",
    "        ensemble_phi_psi_prediction = ensemble_phi_psi_prediction + phi_psi_predictions[base_model]\n",
    "    \n",
    "    if compute_performance_metrics:\n",
    "        average_accuracy_train = average_accuracy_numpy(Q8_labels_train, Q8_predictions[base_model])\n",
    "        total_accuracy_train = total_accuracy_numpy(Q8_labels_train, Q8_predictions[base_model])\n",
    "        total_correct_prediction_train = total_correct_prediction_numpy(Q8_labels_train, Q8_predictions[base_model])\n",
    "        \n",
    "        mean_mae_train = mean_mae_numpy_train(phi_psi_labels_train, phi_psi_predictions[base_model])\n",
    "        phi_mae_train = phi_mae_numpy_train(phi_psi_labels_train, phi_psi_predictions[base_model])\n",
    "        psi_mae_train = psi_mae_numpy_train(phi_psi_labels_train, phi_psi_predictions[base_model])\n",
    "        \n",
    "        average_accuracy_test = average_accuracy_numpy(Q8_labels_test, Q8_predictions[base_model])\n",
    "        total_accuracy_test = total_accuracy_numpy(Q8_labels_test, Q8_predictions[base_model])\n",
    "        total_correct_prediction_test = total_correct_prediction_numpy(Q8_labels_test, Q8_predictions[base_model])\n",
    "        \n",
    "        mean_mae_test = mean_mae_numpy_test(phi_psi_labels_test, phi_psi_predictions[base_model])\n",
    "        phi_mae_test = phi_mae_numpy_test(phi_psi_labels_test, phi_psi_predictions[base_model])\n",
    "        psi_mae_test = psi_mae_numpy_test(phi_psi_labels_test, phi_psi_predictions[base_model])\n",
    "        \n",
    "        print(f\"\\n{test_set_name} -- {base_model}:-\")\n",
    "        print(f\"Avg Accuracy [Train/Test]: {average_accuracy_train:.5f}/{average_accuracy_test:.5f}\")\n",
    "        print(f\"Total Accuracy [Train/Test]: {total_accuracy_train:.5f}/{total_accuracy_test:.5f}\")\n",
    "        print(f\"Total Correct Prediction [Train/Test]: {total_correct_prediction_train:.2f}/{total_correct_prediction_test:.2f}\")\n",
    "        print(f\"Mean MAE [Train/Test]: {mean_mae_train:.4f}/{mean_mae_test:.4f}\")\n",
    "        print(f\"Phi MAE [Train/Test]: {phi_mae_train:.4f}/{phi_mae_test:.4f}\")\n",
    "        print(f\"Psi MAE [Train/Test]: {psi_mae_train:.4f}/{psi_mae_test:.4f}\")\n",
    "\n",
    "if len(base_models) > 1:\n",
    "    ensemble_Q8_prediction = softmax(ensemble_Q8_prediction, axis=-1)\n",
    "    ensemble_phi_psi_prediction = ensemble_phi_psi_prediction / len(base_models)\n",
    "    \n",
    "    if compute_performance_metrics:\n",
    "        average_accuracy_train = average_accuracy_numpy(Q8_labels_train, ensemble_Q8_prediction)\n",
    "        total_accuracy_train = total_accuracy_numpy(Q8_labels_train, ensemble_Q8_prediction)\n",
    "        total_correct_prediction_train = total_correct_prediction_numpy(Q8_labels_train, ensemble_Q8_prediction)\n",
    "        \n",
    "        mean_mae_train = mean_mae_numpy_train(phi_psi_labels_train, ensemble_phi_psi_prediction)\n",
    "        phi_mae_train = phi_mae_numpy_train(phi_psi_labels_train, ensemble_phi_psi_prediction)\n",
    "        psi_mae_train = psi_mae_numpy_train(phi_psi_labels_train, ensemble_phi_psi_prediction)\n",
    "        \n",
    "        average_accuracy_test = average_accuracy_numpy(Q8_labels_test, ensemble_Q8_prediction)\n",
    "        total_accuracy_test = total_accuracy_numpy(Q8_labels_test, ensemble_Q8_prediction)\n",
    "        total_correct_prediction_test = total_correct_prediction_numpy(Q8_labels_test, ensemble_Q8_prediction)\n",
    "        \n",
    "        mean_mae_test = mean_mae_numpy_test(phi_psi_labels_test, ensemble_phi_psi_prediction)\n",
    "        phi_mae_test = phi_mae_numpy_test(phi_psi_labels_test, ensemble_phi_psi_prediction)\n",
    "        psi_mae_test = psi_mae_numpy_test(phi_psi_labels_test, ensemble_phi_psi_prediction)\n",
    "        \n",
    "        print(f\"\\n{test_set_name} -- Ensemble:-\")\n",
    "        print(f\"Avg Accuracy [Train/Test]: {average_accuracy_train:.5f}/{average_accuracy_test:.5f}\")\n",
    "        print(f\"Total Accuracy [Train/Test]: {total_accuracy_train:.5f}/{total_accuracy_test:.5f}\")\n",
    "        print(f\"Total Correct Prediction [Train/Test]: {total_correct_prediction_train:.2f}/{total_correct_prediction_test:.2f}\")\n",
    "        print(f\"Mean MAE [Train/Test]: {mean_mae_train:.4f}/{mean_mae_test:.4f}\")\n",
    "        print(f\"Phi MAE [Train/Test]: {phi_mae_train:.4f}/{phi_mae_test:.4f}\")\n",
    "        print(f\"Psi MAE [Train/Test]: {psi_mae_train:.4f}/{psi_mae_test:.4f}\")\n",
    "    \n",
    "    base_models.append(ensemble_name)\n",
    "    Q8_predictions[ensemble_name] = ensemble_Q8_prediction\n",
    "    phi_psi_predictions[ensemble_name] = ensemble_phi_psi_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing and Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_predicted_labels:\n",
    "    if not os.path.exists(\"../Outputs\" + os.sep + test_set_name):\n",
    "        os.makedirs(\"../Outputs\" + os.sep + test_set_name)\n",
    "    \n",
    "    ss_s = ['G', 'H', 'I', 'B', 'E', 'S', 'T', 'C']\n",
    "    \n",
    "    for base_model in base_models:\n",
    "        if not os.path.exists(\"../Outputs\" + os.sep + test_set_name + os.sep + base_model):\n",
    "            os.makedirs(\"../Outputs\" + os.sep + test_set_name + os.sep + base_model)\n",
    "        \n",
    "        for index, protein_name in enumerate(test_protein_names):\n",
    "            with open(f\"{test_set_path}/Rawdata/{protein_name}/{protein_name}.fasta\", 'r') as fasta_file:\n",
    "                pseq = fasta_file.read().split('\\n')[1]\n",
    "            \n",
    "            assert len(pseq) == test_proteins_dict[protein_name]\n",
    "            \n",
    "            Q8_prediction = Q8_predictions[base_model][index, :len(pseq)]\n",
    "            phi_psi_prediction = phi_psi_predictions[base_model][index, :len(pseq)]\n",
    "            \n",
    "            sseq, max_indices = \"\", np.argmax(Q8_prediction, axis=-1)\n",
    "            \n",
    "            for max_index in max_indices:\n",
    "                sseq = sseq + ss_s[max_index]\n",
    "            \n",
    "            phi_angles = np.arctan2(phi_psi_prediction[:, 0], phi_psi_prediction[:, 1]) * 180 / np.pi\n",
    "            psi_angles = np.arctan2(phi_psi_prediction[:, 2], phi_psi_prediction[:, 3]) * 180 / np.pi\n",
    "            \n",
    "            phi_angles[0] = psi_angles[len(pseq) - 1] = -500\n",
    "            \n",
    "            assert len(pseq) == len(sseq) == phi_angles.shape[0] == psi_angles.shape[0]\n",
    "            \n",
    "            outputs = pd.DataFrame({\"Amino Acid\": list(pseq), \"SS\": list(sseq), \"Phi\": phi_angles, \"Psi\": psi_angles})\n",
    "            outputs.to_csv(f\"../Outputs/{test_set_name}/{base_model}/{protein_name}.csv\", index=False)\n",
    "\n",
    "inference_required_time = time.time() - inference_start_time\n",
    "\n",
    "print(f\"\\nDone! ~ Inference and labels generation took {inference_required_time} seconds.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "rb3u5tpY4gB0",
    "7PeiV9KK4rOc",
    "YnF1fuYu5ViH",
    "JiCJR4goHK9y",
    "f2LZtgGh6cZk",
    "kS0AzYuF5Aua"
   ],
   "name": "Inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
